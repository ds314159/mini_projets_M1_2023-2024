# Ce pipe, propose d'entrer un fichier de nouvelles observations et de réaliser la prédiction dessus
# Tout en enregistrant un fichier des prédiction pour ces observations.

import pandas as pd
import numpy as np
import pickle
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
# Désactiver les warnings
import warnings
warnings.filterwarnings("ignore")
# Spécifier le chemin vers le répertoire de travail
import os
repertoire = './'
os.chdir(repertoire)

# spécifier le nom du fichier à importer , sur lequel il y aura la prédiction
fichier_de_travail = "clients_achats.xlsx"

# Fonction simple de normalisation de variables qualitatives encodées, à intégrer dans le pipe.
def normalisation_OHE(X):
    mean = X.mean(axis=0)
    return X / np.sqrt(mean)


# Charger le modèle KMeans
with open('modele_clustering_exploitable.pkl', 'rb') as fichier:
    km = pickle.load(fichier)


# Charger les nouvelles données
nouvelles_donnees = pd.read_excel(fichier_de_travail, sheet_name="var_actives")
# enlever la colonne insignifiante
nouvelles_donnees = nouvelles_donnees.iloc[:, 1:]

# Identifications des types de colonnes pour la transformation
colonnes_qualitatives = nouvelles_donnees.select_dtypes(include=['object']).columns
colonnes_quantitatives = nouvelles_donnees.select_dtypes(exclude=['object']).columns

# Construire les prétraitements automatisés des colonnes qualitatives et quantitatives
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), colonnes_quantitatives),
        ('cat', Pipeline([
            ('onehot', OneHotEncoder()),
            ('normalize', FunctionTransformer(normalisation_OHE))
        ]), colonnes_qualitatives)
    ])

# Construire le pipeline incluant la préparation des données, la transformation  et le modèle de clustering
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('pca', PCA(n_components=11)),
    ('model', km)
])

# Application du pipeline aux nouvelles données pour effectuer les prédictions
predictions = pipeline.fit_predict(nouvelles_donnees)

print(f'Le clustering sur les nouvelles données s\'est bien déroulé et en voilà le resultat : {predictions}')

# Sauvegarde du fichier incluant la nouvelle colonne de clusters
df_sauvegarde = nouvelles_donnees.copy()
df_sauvegarde['clusters'] = predictions
print(df_sauvegarde.head())
# Enregistrer le DataFrame avec les prédictions dans un nouveau fichier
df_sauvegarde.to_excel("resultat_clustering.xlsx", index=False)

