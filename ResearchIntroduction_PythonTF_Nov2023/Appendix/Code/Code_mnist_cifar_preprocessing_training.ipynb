{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0cf400",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad0cf400",
        "outputId": "73fdb7cd-42c8-4154-bf52-d22671395c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# importation de bibliothèques:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, LSTM, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Installation du drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Spécifier le chemin du dossier de destination dans Google Drive\n",
        "base_path = '/content/drive/My Drive/initiation_recherche/final/'\n",
        "\n",
        "# Fonctions personnelles de sauvegarde de resultats\n",
        "\n",
        "def save_with_pickle(obj, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(obj, file)\n",
        "\n",
        "# Fonction pour charger les données depuis un fichier pickle\n",
        "def load_pkl(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        return pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf36420",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adf36420",
        "outputId": "c6d39a1b-f4c3-4824-acc0-b3007f3dd26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Télécharger les ensembles de données MNIST et CIFAR-10\n",
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()\n",
        "(cifar_train_images, cifar_train_labels), (cifar_test_images, cifar_test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normaliser les images pour MNIST et CIFAR-10\n",
        "mnist_train_images = mnist_train_images.astype('float32') / 255.0\n",
        "mnist_test_images = mnist_test_images.astype('float32') / 255.0\n",
        "cifar_train_images = cifar_train_images.astype('float32') / 255.0\n",
        "cifar_test_images = cifar_test_images.astype('float32') / 255.0\n",
        "\n",
        "# Redimensionner les images MNIST pour le modèle CNN (ajout d'un canal)\n",
        "mnist_train_images_cnn = mnist_train_images.reshape((-1, 28, 28, 1))\n",
        "mnist_test_images_cnn = mnist_test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Redimensionner les images CIFAR-10 pour le modèle CNN\n",
        "cifar_train_images_cnn = cifar_train_images.reshape((-1, 32, 32, 3))\n",
        "cifar_test_images_cnn = cifar_test_images.reshape((-1, 32, 32, 3))\n",
        "\n",
        "# Redimensionner les images CIFAR-10 pour le modèle RNN\n",
        "cifar_train_images_rnn = cifar_train_images.reshape((-1, 32, 32 * 3))  # Redimensionner en (32, 96)\n",
        "cifar_test_images_rnn = cifar_test_images.reshape((-1, 32, 32 * 3))\n",
        "\n",
        "# One-hot encoding des étiquettes pour MNIST et CIFAR-10\n",
        "mnist_train_labels = to_categorical(mnist_train_labels, 10)\n",
        "mnist_test_labels = to_categorical(mnist_test_labels, 10)\n",
        "cifar_train_labels = to_categorical(cifar_train_labels, 10)\n",
        "cifar_test_labels = to_categorical(cifar_test_labels, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596ccf7e",
      "metadata": {
        "id": "596ccf7e"
      },
      "source": [
        "## modèles CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe07cc7",
      "metadata": {
        "id": "dbe07cc7"
      },
      "outputs": [],
      "source": [
        "# modèle CNN pour mnist :\n",
        "model_cnn_mnist = Sequential([\n",
        "    Conv2D(256, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Adapté pour CIFAR-10\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n",
        "\n",
        "\n",
        "# Modèle CNN pour CIFAR-10\n",
        "model_cnn_cifar = Sequential([\n",
        "    Conv2D(256, (3, 3), activation='relu', input_shape=(32, 32, 3)),  # Adapté pour CIFAR-10\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23c73012",
      "metadata": {
        "id": "23c73012"
      },
      "source": [
        "## modèles RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7dfa46",
      "metadata": {
        "id": "2f7dfa46"
      },
      "outputs": [],
      "source": [
        "# modèle RNN :\n",
        "model_rnn_mnist = Sequential([\n",
        "    LSTM(512, return_sequences=True, input_shape=(28, 28)),  # 32 lignes de 32x3 pixels\n",
        "    BatchNormalization(),\n",
        "    LSTM(256),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n",
        "\n",
        "# Modèle RNN pour CIFAR-10\n",
        "model_rnn_cifar = Sequential([\n",
        "    LSTM(512, return_sequences=True, input_shape=(32, 96)),  # 32 lignes de 32x3 pixels\n",
        "    BatchNormalization(),\n",
        "    LSTM(256),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105f4da5",
      "metadata": {
        "id": "105f4da5"
      },
      "source": [
        "## modèles DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685fe340",
      "metadata": {
        "id": "685fe340"
      },
      "outputs": [],
      "source": [
        "# modèle DNN\n",
        "model_dnn_mnist = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),   # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),   # 64 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n",
        "\n",
        "# Modèle DNN pour CIFAR-10\n",
        "model_dnn_cifar = Sequential([\n",
        "    Flatten(input_shape=(32, 32, 3)),  # Adapté pour CIFAR-10\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),  # 512 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),  # 256 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),  # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),   # 128 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),   # 64 neurones\n",
        "    BatchNormalization(),\n",
        "    Dense(10, activation='softmax')  # 10 classes pour CIFAR-10\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e6ca2d",
      "metadata": {
        "id": "68e6ca2d"
      },
      "outputs": [],
      "source": [
        "# compiler modèles :\n",
        "\n",
        "models_mnist = [model_cnn_mnist, model_rnn_mnist, model_dnn_mnist]\n",
        "for model in models_mnist:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "models_cifar = [model_cnn_cifar, model_rnn_cifar, model_dnn_cifar]\n",
        "for model in models_cifar:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee18500",
      "metadata": {
        "id": "4ee18500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ac0454-7131-4b5e-ceda-c201a828d13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résumé du modèle CNN mnist:\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 256)       2560      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 26, 26, 256)       1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 256)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 11, 11, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 9, 9, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               524416    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1719882 (6.56 MB)\n",
            "Trainable params: 1717962 (6.55 MB)\n",
            "Non-trainable params: 1920 (7.50 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Résumé du modèle RNN mnist:\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 28, 512)           1107968   \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 28, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2000010 (7.63 MB)\n",
            "Trainable params: 1997706 (7.62 MB)\n",
            "Non-trainable params: 2304 (9.00 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Résumé du modèle DNN mnist:\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_24 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 64)                256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738570 (6.63 MB)\n",
            "Trainable params: 1731530 (6.61 MB)\n",
            "Non-trainable params: 7040 (27.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# MNIST\n",
        "\n",
        "# Pour le modèle CNN mnist\n",
        "print(\"Résumé du modèle CNN mnist:\")\n",
        "model_cnn_mnist.summary()\n",
        "\n",
        "# Pour le modèle RNN mnist\n",
        "print(\"\\nRésumé du modèle RNN mnist:\")\n",
        "model_rnn_mnist.summary()\n",
        "\n",
        "# Pour le modèle DNN\n",
        "print(\"\\nRésumé du modèle DNN mnist:\")\n",
        "model_dnn_mnist.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e67594",
      "metadata": {
        "id": "82e67594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78d4b15-841e-43ca-fee5-90b6eac7b2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résumé du modèle CNN cifar:\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 256)       7168      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 30, 30, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 13, 13, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 11, 11, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               819328    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2019402 (7.70 MB)\n",
            "Trainable params: 2017482 (7.70 MB)\n",
            "Non-trainable params: 1920 (7.50 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Résumé du modèle RNN cifar:\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 32, 512)           1247232   \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 32, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2139274 (8.16 MB)\n",
            "Trainable params: 2136970 (8.15 MB)\n",
            "Non-trainable params: 2304 (9.00 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Résumé du modèle DNN cifar:\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               1573376   \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_35 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_36 (Ba  (None, 64)                256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2115914 (8.07 MB)\n",
            "Trainable params: 2111946 (8.06 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CIFAR :\n",
        "\n",
        "# Pour le modèle CNN\n",
        "print(\"Résumé du modèle CNN cifar:\")\n",
        "model_cnn_cifar.summary()\n",
        "\n",
        "# Pour le modèle RNN\n",
        "print(\"\\nRésumé du modèle RNN cifar:\")\n",
        "model_rnn_cifar.summary()\n",
        "\n",
        "# Pour le modèle DNN\n",
        "print(\"\\nRésumé du modèle DNN cifar:\")\n",
        "model_dnn_cifar.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7872a18e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7872a18e",
        "outputId": "0e6297bd-82ad-424d-a137-f8e7b98d3cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 15s 9ms/step - loss: 0.0925 - accuracy: 0.9729 - val_loss: 0.0391 - val_accuracy: 0.9873\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.0321 - val_accuracy: 0.9889\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.0281 - val_accuracy: 0.9905\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0237 - val_accuracy: 0.9921\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.2220 - val_accuracy: 0.9552\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0322 - val_accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0229 - val_accuracy: 0.9936\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0243 - val_accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0324 - val_accuracy: 0.9908\n",
            "Temps d'entraînement : 89.96 secondes\n"
          ]
        }
      ],
      "source": [
        "# entrainement CNN MNIST :\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "history_cnn_mnist = model_cnn_mnist.fit(mnist_train_images_cnn,\n",
        "                                        mnist_train_labels,\n",
        "                                        epochs=10,\n",
        "                                        batch_size=64,\n",
        "                                        validation_data=(mnist_test_images_cnn, mnist_test_labels))\n",
        "\n",
        "training_time_cnn_mnist = time.time() - start_time\n",
        "\n",
        "print(f'Temps d\\'entraînement : {training_time_cnn_mnist:.2f} secondes')\n",
        "\n",
        "# Pour le modèle CNN MNIST\n",
        "\n",
        "\n",
        "save_with_pickle(history_cnn_mnist, base_path + 'history_cnn_mnist_accuracy.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee5d06e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ee5d06e",
        "outputId": "2b2522b7-2462-4895-d6f6-ed6d16dc11ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 12s 11ms/step - loss: 1.2956 - accuracy: 0.5394 - val_loss: 1.9294 - val_accuracy: 0.3391\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.8637 - accuracy: 0.6986 - val_loss: 1.2636 - val_accuracy: 0.5667\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6630 - accuracy: 0.7684 - val_loss: 0.9220 - val_accuracy: 0.6858\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5084 - accuracy: 0.8234 - val_loss: 0.9238 - val_accuracy: 0.6996\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.3749 - accuracy: 0.8718 - val_loss: 0.9047 - val_accuracy: 0.7136\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2591 - accuracy: 0.9116 - val_loss: 1.1503 - val_accuracy: 0.6715\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1911 - accuracy: 0.9345 - val_loss: 1.1612 - val_accuracy: 0.7040\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1469 - accuracy: 0.9490 - val_loss: 1.0915 - val_accuracy: 0.7272\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1207 - accuracy: 0.9589 - val_loss: 1.1762 - val_accuracy: 0.7123\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1014 - accuracy: 0.9654 - val_loss: 1.0788 - val_accuracy: 0.7463\n",
            "Temps d'entraînement : 85.20 secondes\n"
          ]
        }
      ],
      "source": [
        "# Entraînement du modèle CNN pour CIFAR-10\n",
        "start_time = time.time()\n",
        "\n",
        "history_cnn_cifar = model_cnn_cifar.fit(cifar_train_images_cnn,\n",
        "                                        cifar_train_labels,\n",
        "                                        epochs=10,\n",
        "                                        batch_size=64,\n",
        "                                        validation_data=(cifar_test_images_cnn, cifar_test_labels)  # Données de validation pour CIFAR-10\n",
        ")\n",
        "\n",
        "training_time_cnn_cifar = time.time() - start_time\n",
        "print(f'Temps d\\'entraînement : {training_time_cnn_cifar:.2f} secondes')\n",
        "\n",
        "# Pour le modèle CNN CIFAR-10\n",
        "\n",
        "save_with_pickle(history_cnn_cifar, base_path + 'history_cnn_cifar_accuracy.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91218cd0",
      "metadata": {
        "id": "91218cd0"
      },
      "outputs": [],
      "source": [
        "# Graphes CNN MNIST\n",
        "\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_cnn_mnist.history['loss'], label='Train Loss')\n",
        "plt.plot(history_cnn_mnist.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_cnn_mnist.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_cnn_mnist.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6bdd47",
      "metadata": {
        "id": "6d6bdd47"
      },
      "outputs": [],
      "source": [
        "# Graphes CNN cifar\n",
        "\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_cnn_cifar.history['loss'], label='Train Loss')\n",
        "plt.plot(history_cnn_cifar.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_cnn_cifar.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_cnn_cifar.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ad8c5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ad8c5a",
        "outputId": "53097cd8-c7d3-4041-f7c4-c02862898d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 16s 11ms/step - loss: 0.2855 - accuracy: 0.9077 - val_loss: 0.1379 - val_accuracy: 0.9584\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.1062 - accuracy: 0.9675 - val_loss: 0.1056 - val_accuracy: 0.9682\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.0840 - val_accuracy: 0.9762\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.0801 - val_accuracy: 0.9767\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0515 - accuracy: 0.9838 - val_loss: 0.0532 - val_accuracy: 0.9826\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.0567 - val_accuracy: 0.9833\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.0446 - val_accuracy: 0.9869\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.0406 - val_accuracy: 0.9877\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.0505 - val_accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
            "Temps d'entraînement : 106.53 secondes\n"
          ]
        }
      ],
      "source": [
        "# entrainement RNN mnist\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "history_rnn_mnist = model_rnn_mnist.fit(mnist_train_images,\n",
        "                            mnist_train_labels,\n",
        "                            epochs=10,\n",
        "                            batch_size=64,\n",
        "                            validation_data=(mnist_test_images, mnist_test_labels))\n",
        "\n",
        "training_time_rnn_mnist = time.time() - start_time\n",
        "\n",
        "print(f'Temps d\\'entraînement : {training_time_rnn_mnist:.2f} secondes')\n",
        "\n",
        "# sauvegarder le résultat\n",
        "\n",
        "save_with_pickle(history_rnn_mnist, base_path + 'history_rnn_mnist_accuracy.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd51b82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dd51b82",
        "outputId": "036f0ecf-a680-420c-8c1f-053d465b491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 15s 13ms/step - loss: 1.7904 - accuracy: 0.3534 - val_loss: 3.0948 - val_accuracy: 0.1417\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.4804 - accuracy: 0.4644 - val_loss: 1.5547 - val_accuracy: 0.4225\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.3276 - accuracy: 0.5215 - val_loss: 1.4512 - val_accuracy: 0.4826\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.2197 - accuracy: 0.5597 - val_loss: 1.4030 - val_accuracy: 0.4998\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.1285 - accuracy: 0.5949 - val_loss: 1.2410 - val_accuracy: 0.5610\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.0526 - accuracy: 0.6253 - val_loss: 1.3607 - val_accuracy: 0.5319\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9726 - accuracy: 0.6512 - val_loss: 1.2077 - val_accuracy: 0.5786\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9090 - accuracy: 0.6732 - val_loss: 1.1919 - val_accuracy: 0.5882\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.8373 - accuracy: 0.7000 - val_loss: 1.1362 - val_accuracy: 0.6021\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7637 - accuracy: 0.7258 - val_loss: 1.2136 - val_accuracy: 0.5887\n",
            "Temps d'entraînement : 97.75 secondes\n"
          ]
        }
      ],
      "source": [
        "# Entraînement du modèle RNN pour CIFAR-10\n",
        "start_time = time.time()\n",
        "\n",
        "history_rnn_cifar = model_rnn_cifar.fit(cifar_train_images_rnn,\n",
        "                                        cifar_train_labels,\n",
        "                                        epochs=10,\n",
        "                                        batch_size=64,\n",
        "                                        validation_data=(cifar_test_images_rnn, cifar_test_labels))\n",
        "\n",
        "training_time_rnn_cifar = time.time() - start_time\n",
        "print(f'Temps d\\'entraînement : {training_time_rnn_cifar:.2f} secondes')\n",
        "\n",
        "# sauvegarder le résultat\n",
        "\n",
        "save_with_pickle(history_rnn_cifar, base_path + 'history_rnn_cifar_accuracy.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340fecbc",
      "metadata": {
        "id": "340fecbc"
      },
      "outputs": [],
      "source": [
        "# Graphes RNN mnist\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_rnn_mnist.history['loss'], label='Train Loss')\n",
        "plt.plot(history_rnn_mnist.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_rnn_mnist.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_rnn_mnist.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de139ae8",
      "metadata": {
        "id": "de139ae8"
      },
      "outputs": [],
      "source": [
        "# Graphes RNN cifar\n",
        "\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_rnn_cifar.history['loss'], label='Train Loss')\n",
        "plt.plot(history_rnn_cifar.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_rnn_cifar.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_rnn_cifar.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8897c7f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8897c7f0",
        "outputId": "6f80ee42-70ce-452d-8e1c-d6e806d7a95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 19s 13ms/step - loss: 0.3243 - accuracy: 0.9031 - val_loss: 0.1843 - val_accuracy: 0.9514\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.1682 - accuracy: 0.9512 - val_loss: 0.1257 - val_accuracy: 0.9642\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.1399 - accuracy: 0.9592 - val_loss: 0.1281 - val_accuracy: 0.9611\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.1260 - accuracy: 0.9643 - val_loss: 0.0958 - val_accuracy: 0.9702\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.1069 - accuracy: 0.9695 - val_loss: 0.0806 - val_accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0992 - accuracy: 0.9718 - val_loss: 0.1051 - val_accuracy: 0.9707\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0895 - accuracy: 0.9748 - val_loss: 0.0851 - val_accuracy: 0.9764\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0752 - accuracy: 0.9791 - val_loss: 0.0829 - val_accuracy: 0.9774\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.0947 - val_accuracy: 0.9735\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0588 - accuracy: 0.9835 - val_loss: 0.1255 - val_accuracy: 0.9695\n",
            "Temps d'entraînement : 126.46 secondes\n"
          ]
        }
      ],
      "source": [
        "# entrainement DNN mnist\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "history_dnn_mnist = model_dnn_mnist.fit(mnist_train_images,\n",
        "                            mnist_train_labels,\n",
        "                            epochs=10,\n",
        "                            batch_size=64,\n",
        "                            validation_data=(mnist_test_images, mnist_test_labels))\n",
        "\n",
        "training_time_dnn_mnist = time.time() - start_time\n",
        "\n",
        "print(f'Temps d\\'entraînement : {training_time_dnn_mnist:.2f} secondes')\n",
        "\n",
        "# sauvegarder le résultat\n",
        "\n",
        "save_with_pickle(history_dnn_mnist, base_path + 'history_dnn_mnist_accuracy.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce20562",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ce20562",
        "outputId": "84c5596c-39a7-48bb-cd51-59f5f514f529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 14s 11ms/step - loss: 1.8365 - accuracy: 0.3440 - val_loss: 1.8035 - val_accuracy: 0.3569\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.6357 - accuracy: 0.4136 - val_loss: 1.7311 - val_accuracy: 0.3691\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.5452 - accuracy: 0.4480 - val_loss: 1.8852 - val_accuracy: 0.3357\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.4859 - accuracy: 0.4689 - val_loss: 1.8627 - val_accuracy: 0.3670\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.4324 - accuracy: 0.4904 - val_loss: 1.6841 - val_accuracy: 0.4086\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.3807 - accuracy: 0.5094 - val_loss: 1.4352 - val_accuracy: 0.4887\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.3343 - accuracy: 0.5234 - val_loss: 1.5524 - val_accuracy: 0.4525\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.2922 - accuracy: 0.5431 - val_loss: 1.4368 - val_accuracy: 0.4903\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.2480 - accuracy: 0.5567 - val_loss: 1.6726 - val_accuracy: 0.4180\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.2161 - accuracy: 0.5679 - val_loss: 1.4469 - val_accuracy: 0.4830\n",
            "Temps d'entraînement : 85.94 secondes\n"
          ]
        }
      ],
      "source": [
        "# Entraînement du modèle DNN pour CIFAR-10\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history_dnn_cifar = model_dnn_cifar.fit(cifar_train_images,\n",
        "                                        cifar_train_labels,\n",
        "                                        epochs=10,\n",
        "                                        batch_size=64,\n",
        "                                        validation_data=(cifar_test_images, cifar_test_labels)\n",
        ")\n",
        "\n",
        "training_time_dnn_cifar = time.time() - start_time\n",
        "print(f'Temps d\\'entraînement : {training_time_dnn_cifar:.2f} secondes')\n",
        "\n",
        "# sauvegarder le résultat\n",
        "\n",
        "save_with_pickle(history_dnn_cifar, base_path + 'history_dnn_cifar_accuracy.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecee7a8a",
      "metadata": {
        "id": "ecee7a8a"
      },
      "outputs": [],
      "source": [
        "# Graphes DNN mnist\n",
        "\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_dnn_mnist.history['loss'], label='Train Loss')\n",
        "plt.plot(history_dnn_mnist.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_dnn_mnist.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_dnn_mnist.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fc40a1",
      "metadata": {
        "id": "46fc40a1"
      },
      "outputs": [],
      "source": [
        "# Graphes DNN cifar\n",
        "\n",
        "# Tracer la perte\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_dnn_cifar.history['loss'], label='Train Loss')\n",
        "plt.plot(history_dnn_cifar.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Tracer la précision\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_dnn_cifar.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_dnn_cifar.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413ab171",
      "metadata": {
        "id": "413ab171"
      },
      "outputs": [],
      "source": [
        "# Rapports de classification\n",
        "\n",
        "# fonction d'impression d e rapport de classification :\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "def print_classification_report(model, X_test, y_test, model_name):\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    y_test_argmax = np.argmax(y_test, axis=1) # Si les étiquettes sont en one-hot encoding\n",
        "    report = classification_report(y_test_argmax, predictions)\n",
        "    print(f\"Rapport de classification pour {model_name}:\\n\")\n",
        "    print(report)\n",
        "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# Exemple d'appel de la fonction pour chaque modèle\n",
        "print_classification_report(model_cnn_mnist, mnist_test_images_cnn, mnist_test_labels, \"CNN sur MNIST\")\n",
        "print_classification_report(model_cnn_cifar, cifar_test_images_cnn, cifar_test_labels, \"CNN sur CIFAR-10\")\n",
        "print_classification_report(model_rnn_mnist, mnist_test_images_rnn, mnist_test_labels, \"RNN sur MNIST\")\n",
        "print_classification_report(model_rnn_cifar, cifar_test_images_rnn, cifar_test_labels, \"RNN sur CIFAR-10\")\n",
        "print_classification_report(model_dnn_mnist, mnist_test_images_dnn, mnist_test_labels, \"DNN sur MNIST\")\n",
        "print_classification_report(model_dnn_cifar, cifar_test_images_dnn, cifar_test_labels, \"DNN sur CIFAR-10\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "096ZD2XvmiOv"
      },
      "id": "096ZD2XvmiOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyzxul1emmP8"
      },
      "id": "fyzxul1emmP8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "61dd5eac",
      "metadata": {
        "id": "61dd5eac"
      },
      "source": [
        "# Comparatifs :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8cb035",
      "metadata": {
        "id": "6c8cb035"
      },
      "outputs": [],
      "source": [
        "# comparatif :\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chargement des historiques pour chaque modèle\n",
        "\n",
        "# history_cnn = load_pkl('history_cnn.pkl')\n",
        "# history_rnn = load_pkl('history_rnn.pkl')\n",
        "# history_dnn = load_pkl('history_dnn.pkl')\n",
        "\n",
        "# Fonction pour tracer les courbes de perte et de précision\n",
        "def plot_history(histories, title):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Tracé des pertes\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for name, history in histories:\n",
        "        plt.plot(history['loss'], label=f'{name} Train')\n",
        "        plt.plot(history['val_loss'], label=f'{name} Validation')\n",
        "    plt.title('Loss - ' + title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Tracé des précisions\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for name, history in histories:\n",
        "        plt.plot(history['accuracy'], label=f'{name} Train')\n",
        "        plt.plot(history['val_accuracy'], label=f'{name} Validation')\n",
        "    plt.title('Accuracy - ' + title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Comparaison des modèles\n",
        "plot_history([('CNN', history_cnn), ('RNN', history_rnn), ('DNN', history_dnn)], 'Model Comparison')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6722113",
      "metadata": {
        "id": "e6722113"
      },
      "outputs": [],
      "source": [
        "# matrice de confusion\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(model, X_test, y_test, title):\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    y_test_argmax = np.argmax(y_test, axis=1) # Si les étiquettes sont en one-hot encoding\n",
        "    cm = confusion_matrix(y_test_argmax, predictions)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.title('Confusion Matrix - ' + title)\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# plot_confusion_matrix(model_cnn, mnist_test_images_cnn, mnist_test_labels, 'CNN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69492ef",
      "metadata": {
        "id": "e69492ef"
      },
      "outputs": [],
      "source": [
        "# rapport de classification\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def print_classification_report(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    y_test_argmax = np.argmax(y_test, axis=1) # Si les étiquettes sont en one-hot encoding\n",
        "    report = classification_report(y_test_argmax, predictions)\n",
        "    print(report)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# print_classification_report(model_cnn, mnist_test_images_cnn, mnist_test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93744937",
      "metadata": {
        "id": "93744937"
      },
      "outputs": [],
      "source": [
        "# courbe roc et auc :\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def plot_roc_curve(model, X_test, y_test, num_classes):\n",
        "    # Prédictions et One-hot encoding si nécessaire\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "    # Calcul de la courbe ROC pour chaque classe\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_cat[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Tracer toutes les courbes ROC\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(num_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation pour une classification multi-classes\n",
        "# plot_roc_curve(model_cnn, mnist_test_images_cnn, mnist_test_labels, num_classes=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "320653c8",
      "metadata": {
        "id": "320653c8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}